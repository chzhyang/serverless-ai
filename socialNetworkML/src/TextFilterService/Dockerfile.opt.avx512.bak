FROM intel/intel-optimized-tensorflow-avx512:2.5.0

#ENV http_proxy=http://proxy-fm.intel.com:911
#ENV https_proxy=http://proxy-fm.intel.com:912
#ENV no_proxy="10.105.159.2,10.105.159.2,10.105.159.0/24,10.250.0.0/16,10.254.0.0/15,10.253.0.0/16,127.0.0.1,localhost,.svc,.pod,.cluster.local,.svc.cluster.local,.intel.com"

COPY requirements.txt /social-network-microservices/requirements.txt
COPY src/TextFilterService /social-network-microservices/src/TextFilterService
COPY third_party /social-network-microservices/third_party
COPY gen-cpp /social-network-microservices/gen-cpp
COPY gen-lua /social-network-microservices/gen-lua
COPY gen-py /social-network-microservices/gen-py
COPY config /social-network-microservices/config
COPY keys /keys

RUN pip install --no-cache-dir -r /social-network-microservices/requirements.txt
RUN pip install --no-cache-dir joblib==1.0.0 numpy==1.19.5 pandas==1.0.5 scikit-learn==0.24.0 textblob==0.15.3

# Installing transformers from source (with intel-tensorflow-avx512 support)
RUN apt-get update && apt-get install -y git
RUN pip install git+https://github.com/huggingface/transformers.git@fbf1397bf862597aad9f09779abfd5d5d3d84975

# Warm up: download and cache models
RUN python -m textblob.download_corpora
RUN python /social-network-microservices/src/TextFilterService/TextFilterService_cache_models.py

# Run Transformers in a firewalled or a no-network environment.
ENV HF_DATASETS_OFFLINE=1
ENV TRANSFORMERS_OFFLINE=1

WORKDIR /social-network-microservices/src/TextFilterService
ENV TF_ENABLE_ONEDNN_OPTS=1
ENV OMP_NUM_THREADS=8
# ENV KMP_AFFINITY=granularity=fine,verbose,compact,1,0
ENV KMP_AFFINITY=granularity=fine,none,1,0
ENTRYPOINT ["python", "TextFilterService.py", "--num_intra_threads=8", "--num_inter_threads=2"]
# ENTRYPOINT ["python", "TextFilterService.py"]
